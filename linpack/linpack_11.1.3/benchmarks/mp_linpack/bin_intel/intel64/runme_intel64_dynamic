#!/bin/bash
#
echo "This is a SAMPLE run script.  Change it to reflect the correct number"
echo "of CPUs/threads, number of nodes, MPI processes per node, etc.."
#

#
# You can find description of all Intel MPI parameters in the
# Intel MPI Reference Manual.
# See <intel mpi installdir>/doc/Reference_manual.pdf
#

export I_MPI_EAGER_THRESHOLD=128000
#          This setting may give 1-2% of performance increase over the
#          default value of 262000 for large problems and high number of cores

export OUT=xhpl_intel64_dynamic_outputs.txt

date

cp HPL_serial.dat HPL.dat

echo -n "This run was done on: "
date

# Capture some meaningful data for future reference:
echo -n "This run was done on: " >> $OUT
date >> $OUT
echo "HPL.dat: " >> $OUT
cat HPL.dat >> $OUT
echo "Binary name: " >> $OUT
ls -l xhpl_intel64_dynamic >> $OUT
echo "This script: " >> $OUT
cat runme_intel64_dynamic >> $OUT
echo "Environment variables: " >> $OUT
env >> $OUT
echo "Actual run: " >> $OUT

# Environment variables can also be set on the Intel MPI command
# line using the -genv option:

mpiexec -np 4 ./xhpl_intel64_dynamic | tee -a $OUT

# In case of multiple nodes involved, please set the number of MPI processes
# per node (ppn=1,2 typically) through the -perhost option (because the
# default is all cores):

# mpiexec -perhost <ppn> -np <n> ./xhpl_intel64_dynamic

echo -n "Done: " >> $OUT
date >> $OUT

echo -n "Done: "
date
